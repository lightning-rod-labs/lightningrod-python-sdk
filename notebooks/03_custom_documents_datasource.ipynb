{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Custom Document Dataset Generation\n",
        "\n",
        "This notebook demonstrates how to generate forecasting questions from your own documents and files. You can use PDFs, text, CSV or other types of files as a data source for question generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -e ..\n",
        "%pip install dotenv\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from lightningrod import LightningRod\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "api_key = os.getenv(\"LIGHTNINGROD_API_KEY\")\n",
        "base_url = os.getenv(\"LIGHTNINGROD_BASE_URL\", \"https://api.lightningrod.ai/api/public/v1\")\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"LIGHTNINGROD_API_KEY is not set\")\n",
        "\n",
        "# Note: base_url param can be omitted\n",
        "client = LightningRod(api_key=api_key, base_url=base_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## File Chunking and Input Dataset Creation\n",
        "\n",
        "To generate questions from your own documents, we'll need to first chunk them and map each chunk to a \"seed\". The collection of these seeds is treated as the input dataset to the generation pipeline. \n",
        "\n",
        "This approach gives you full control over how your documents are processed and chunked."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created 4 chunks from document\n",
            "First chunk preview: ACME CORPORATION\n",
            "Q1 2025 EARNINGS REPORT\n",
            "\n",
            "EXECUTIVE SUMMARY\n",
            "\n",
            "Acme Corporation (NASDAQ: ACME) today reported financial results for the first quarter ended March 31, 2025. Revenue increased 18% year-ove...\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain-text-splitters\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "with open(\"./data/sample_earnings_report.txt\", \"r\") as f:\n",
        "    document_text = f.read()\n",
        "\n",
        "# Use RecursiveCharacterTextSplitter for more intelligent chunking\n",
        "# It tries to split on paragraphs, sentences, and words in that order\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_text(document_text)\n",
        "print(f\"Created {len(chunks)} chunks from document\\n\")\n",
        "print(f\"First chunk preview: {chunks[0][:200]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Input Dataset from Chunks\n",
        "\n",
        "Now we'll create Sample objects from our chunks and upload them to create an input dataset that can be used for question generation.\n",
        "\n",
        "> Sample is the core data structure that flows through our pipelines and can act both as an input or output of our dataset generation pipelines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created 4 samples from chunks\n"
          ]
        }
      ],
      "source": [
        "from lightningrod import Sample, SampleMeta, Seed\n",
        "\n",
        "samples = []\n",
        "for idx, chunk_text in enumerate(chunks):\n",
        "    seed = Seed(seed_text=chunk_text)\n",
        "    sample_meta = SampleMeta.from_dict({\n",
        "        \"source_file\": \"sample_earnings_report.txt\",\n",
        "        \"chunk_index\": idx,\n",
        "        \"total_chunks\": len(chunks),\n",
        "        \"document_type\": \"earnings_report\",\n",
        "    })\n",
        "    sample = Sample(seed=seed, meta=sample_meta)\n",
        "    samples.append(sample)\n",
        "\n",
        "print(f\"Created {len(samples)} samples from chunks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload Samples to create an Input Dataset\n",
        "\n",
        "Upload the samples to create an input dataset that we can use for question generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CreateDatasetResponse(id='dec982bc-d9e5-43fc-860d-dd66ec8fdaa1', additional_properties={})\n",
            "Created input dataset: dec982bc-d9e5-43fc-860d-dd66ec8fdaa1\n",
            "Total samples: 4\n"
          ]
        }
      ],
      "source": [
        "input_dataset = client.datasets.create_from_samples(samples, batch_size=1000)\n",
        "print(f\"Created input dataset: {input_dataset.id}\")\n",
        "print(f\"Total samples: {input_dataset.num_rows}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure Question Generator\n",
        "\n",
        "Generate questions based on the content of your documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightningrod import AnswerType, AnswerTypeEnum, QuestionAndLabelGenerator\n",
        "\n",
        "qa_config = QuestionAndLabelGenerator(\n",
        "    answer_type=AnswerType(answer_type=AnswerTypeEnum.BINARY),\n",
        "    questions_per_seed=1,\n",
        "    instructions=(\n",
        "        \"Generate binary forecasting questions based on earnings report content. \"\n",
        "        \"Focus on specific future outcomes mentioned in guidance, product launches, market expansion plans, or strategic initiatives. \"\n",
        "        \"Questions must reference concrete metrics, timelines, or events from the document. \"\n",
        "        \"Avoid questions about past performance or historical facts.\"\n",
        "    ),\n",
        "    examples=[\n",
        "        \"Will Acme Corporation meet its Q2 2025 revenue guidance of $2.5-2.6 billion?\",\n",
        "        \"Will the AI-powered analytics platform launch in Q2 2025 as scheduled?\",\n",
        "        \"Will Acme's Asia-Pacific expansion generate at least $50 million in revenue in the second half of 2025?\",\n",
        "        \"Will the Consumer Products Division recover in Q2 2025 as management expects?\",\n",
        "        \"Will EU regulatory changes affect more than 5% of Acme's revenue base if implemented?\",\n",
        "    ],\n",
        "    bad_examples=[\n",
        "        \"Will Acme's cloud services division continue to grow? (too vague - missing specific metrics, timeline, or threshold)\",\n",
        "        \"Will the company face competition in the future? (too generic - not grounded in specific document claims or guidance)\",\n",
        "        \"Will Acme's strategic initiatives be successful? (too vague - doesn't reference concrete outcomes or measurable criteria)\",\n",
        "        \"Will the TechStart acquisition contribute to revenue growth? (missing specific metrics - document mentions $120M annualized revenue but question doesn't reference it)\",\n",
        "        \"Will Acme expand into new markets? (too vague - document specifies Asia-Pacific expansion in Q2 with $50-75M revenue target, but question lacks these details)\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the Pipeline with Input Dataset\n",
        "\n",
        "Pass our input dataset to the transform pipeline. The samples from the input dataset will be used as seeds for question/answer generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chunk_dataset = client.transforms.run(\n",
        "    qa_config, \n",
        "    input_dataset=input_dataset,\n",
        "    max_questions=10 # keep max questions low when testing\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Note: This can take a few minutes to complete processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View the Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install pandas\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 4 samples\n",
            "\n",
            "                              question.question_text label.label  \\\n",
            "0  Will Acme Corporation's Cloud Services Divisio...     Unknown   \n",
            "1  Will Acme Corporation's revenue for Q2 2025 me...         Yes   \n",
            "2  Will Acme's Consumer Products Division recover...         Yes   \n",
            "3  Will the revenue contribution from Acme's top ...     Unknown   \n",
            "\n",
            "   label.label_confidence                                     seed.seed_text  \\\n",
            "0                     1.0  ACME CORPORATION\\nQ1 2025 EARNINGS REPORT\\n\\nE...   \n",
            "1                     1.0  M&A Activity\\nIn March, we completed the acqui...   \n",
            "2                     0.9  Enterprise Software Division\\nRevenue increase...   \n",
            "3                     1.0  RISK FACTORS\\n\\nThe company faces several risk...   \n",
            "\n",
            "   is_valid                        meta.sample_id  meta.chunk_index  \\\n",
            "0      True  f11e4333-e0a4-4ed0-b54c-3af3fc29a32f                 0   \n",
            "1      True  7a60bd68-ae75-41e9-82fe-b801b69bd7ee                 2   \n",
            "2      True  c666339d-1144-415a-9729-0c9e9e36a938                 1   \n",
            "3      True  9ce5b72b-cb43-4c0f-99fb-83c70ffc7f51                 3   \n",
            "\n",
            "             meta.source_file  meta.total_chunks meta.document_type  \\\n",
            "0  sample_earnings_report.txt                  4    earnings_report   \n",
            "1  sample_earnings_report.txt                  4    earnings_report   \n",
            "2  sample_earnings_report.txt                  4    earnings_report   \n",
            "3  sample_earnings_report.txt                  4    earnings_report   \n",
            "\n",
            "                  meta.parent_sample_id  meta.processing_time_ms  \n",
            "0  7ea56481-d14b-4b12-b8b6-7a34cc2530c5                    0.172  \n",
            "1  5b5218e0-8ef5-4f8b-8c06-6e048d4e0308                    0.160  \n",
            "2  65ddb503-51d9-4712-aae7-b2a4420cf755                    0.421  \n",
            "3  2e1bb94d-2a6c-4238-9503-4ab83f9d65c7                    0.481  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Download output samples to memory\n",
        "samples = chunk_dataset.download()\n",
        "print(f\"Generated {chunk_dataset.num_rows} samples\\n\")\n",
        "\n",
        "# Convert cached samples to a list of dictionaries\n",
        "rows = chunk_dataset.flattened()\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (lightningrod-sdk)",
      "language": "python",
      "name": "lightningrod-sdk"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
