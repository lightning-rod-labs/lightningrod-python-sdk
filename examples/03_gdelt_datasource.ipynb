{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GDELT Dataset Generation\n",
        "\n",
        "This notebook demonstrates how to use GDELT (Global Database of Events, Language, and Tone) as a data source for generating forecasting questions. GDELT provides access to a massive database of global news articles via BigQuery, offering broader coverage than standard news search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install lightningrod-ai\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from lightningrod import LightningRod\n",
        "\n",
        "api_key = os.getenv(\"LIGHTNINGROD_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"LIGHTNINGROD_API_KEY is not set\")\n",
        "\n",
        "client = LightningRod(api_key=api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure GDELT Seed Generator\n",
        "\n",
        "GDELT provides access to a much larger corpus of news articles than standard Google News search. It's particularly useful for:\n",
        "- Global events and international news\n",
        "- Historical analysis\n",
        "- Large-scale dataset generation\n",
        "\n",
        "The `GdeltSeedGenerator` queries BigQuery to fetch articles, allowing you to process thousands of articles per interval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from lightningrod import GdeltSeedGenerator\n",
        "\n",
        "gdelt_seed_generator = GdeltSeedGenerator(\n",
        "    start_date=datetime(2025, 1, 1),\n",
        "    end_date=datetime(2025, 1, 31),\n",
        "    interval_duration_days=7,\n",
        "    articles_per_interval=1000,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## When to Use GDELT vs Google News\n",
        "\n",
        "**Use GDELT when:**\n",
        "- You need access to a very large number of articles\n",
        "- You're analyzing global or international events\n",
        "- You need historical data\n",
        "- You want broader coverage across many sources\n",
        "\n",
        "**Use Google News when:**\n",
        "- You need recent, curated news articles\n",
        "- You want more control over search queries\n",
        "- You're working with smaller, focused datasets\n",
        "- You need faster iteration on specific topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightningrod import AnswerType, AnswerTypeEnum, QuestionGenerator, FilterCriteria\n",
        "\n",
        "answer_type = AnswerType(answer_type=AnswerTypeEnum.BINARY)\n",
        "\n",
        "question_generator = QuestionGenerator(\n",
        "    instructions=(\n",
        "        \"Generate forward-looking questions about global events and international news. \"\n",
        "        \"Questions should focus on future outcomes that can be verified.\"\n",
        "    ),\n",
        "    examples=[\n",
        "        \"Will the conflict in region X escalate in the next month?\",\n",
        "        \"Will country Y sign the trade agreement this quarter?\",\n",
        "        \"Will the international summit achieve its stated goals?\",\n",
        "    ],\n",
        "    bad_examples=[\n",
        "        \"What happened in the conflict?\",\n",
        "        \"When was the trade agreement signed?\",\n",
        "        \"Who attended the summit?\",\n",
        "    ],\n",
        "    filter_=FilterCriteria(\n",
        "        rubric=\"The question should be forward-looking and about future global events\",\n",
        "        min_score=0.7\n",
        "    ),\n",
        "    answer_type=answer_type,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightningrod import WebSearchLabeler, QuestionRenderer\n",
        "\n",
        "labeler = WebSearchLabeler(\n",
        "    answer_type=answer_type,\n",
        "    confidence_threshold=0.5,\n",
        ")\n",
        "\n",
        "renderer = QuestionRenderer(\n",
        "    answer_type=answer_type,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the Pipeline\n",
        "\n",
        "The pipeline works the same way as with Google News - GDELT is just a different data source."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightningrod import QuestionPipeline\n",
        "\n",
        "pipeline_config = QuestionPipeline(\n",
        "    seed_generator=gdelt_seed_generator,\n",
        "    question_generator=question_generator,\n",
        "    labeler=labeler,\n",
        "    renderer=renderer,\n",
        ")\n",
        "\n",
        "dataset = client.transforms.run(pipeline_config, max_questions=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install pandas\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Download samples to memory\n",
        "samples = dataset.download()\n",
        "print(f\"Generated {dataset.num_rows} samples\\n\")\n",
        "\n",
        "# Convert cached samples to a list of dictionaries\n",
        "rows = dataset.flattened()\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "print(df.head())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
