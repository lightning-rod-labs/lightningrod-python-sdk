{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Custom Document Dataset Generation\n",
        "\n",
        "This notebook demonstrates how to generate forecasting questions from your own documents and files. You can upload PDFs, reports, internal documents, or any text files and use them as a data source for question generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install lightningrod-ai\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from lightningrod import LightningRod\n",
        "\n",
        "api_key = os.getenv(\"LIGHTNINGROD_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"LIGHTNINGROD_API_KEY is not set\")\n",
        "\n",
        "client = LightningRod(api_key=api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a File Set\n",
        "\n",
        "A file set is a collection of files that can be used together for dataset generation. Files are automatically indexed for RAG-based question generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_set = client.filesets.create(\n",
        "    name=\"Company Reports 2025\",\n",
        "    description=\"Quarterly earnings reports and company documents\"\n",
        ")\n",
        "\n",
        "print(f\"Created file set: {file_set.name} (ID: {file_set.id})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload Files\n",
        "\n",
        "Upload your documents to the file set. You can add metadata to help organize and filter files later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = Path(\"sample_earnings_report.txt\")\n",
        "\n",
        "if file_path.exists():\n",
        "    uploaded_file = client.filesets.files.upload(\n",
        "        file_set_id=file_set.id,\n",
        "        file_path=file_path,\n",
        "        metadata={\n",
        "            \"document_type\": \"earnings_report\",\n",
        "            \"quarter\": \"Q1\",\n",
        "            \"year\": 2025,\n",
        "        }\n",
        "    )\n",
        "    print(f\"Uploaded: {uploaded_file.original_file_name}\")\n",
        "else:\n",
        "    print(f\"Note: Create a {file_path} file to test file upload\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## List Files in File Set\n",
        "\n",
        "Verify that your files are in the file set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files_response = client.filesets.files.list(file_set.id)\n",
        "print(f\"Files in set: {files_response.total}\")\n",
        "for file in files_response.files:\n",
        "    print(f\"  - {file.original_file_name} ({file.size_bytes} bytes)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure Document-Based Seed Generator\n",
        "\n",
        "The `FileSetSeedGenerator` extracts text from your uploaded files and chunks them into seeds for question generation. Files are automatically processed and indexed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightningrod import FileSetSeedGenerator\n",
        "\n",
        "file_set_seed_generator = FileSetSeedGenerator(\n",
        "    file_set_id=file_set.id,\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure Question Generator\n",
        "\n",
        "Generate questions based on the content of your documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightningrod import AnswerType, AnswerTypeEnum, QuestionGenerator\n",
        "\n",
        "answer_type = AnswerType(answer_type=AnswerTypeEnum.BINARY)\n",
        "\n",
        "question_generator = QuestionGenerator(\n",
        "    instructions=(\n",
        "        \"Generate forward-looking questions based on the document content. \"\n",
        "        \"Questions should be about future events or outcomes mentioned or implied in the documents.\"\n",
        "    ),\n",
        "    examples=[\n",
        "        \"Will the company meet its revenue target for Q2?\",\n",
        "        \"Will the new product launch be delayed?\",\n",
        "        \"Will the merger be completed this year?\",\n",
        "    ],\n",
        "    answer_type=answer_type,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightningrod import WebSearchLabeler, QuestionRenderer\n",
        "\n",
        "labeler = WebSearchLabeler(answer_type=answer_type)\n",
        "renderer = QuestionRenderer(answer_type=answer_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the Pipeline\n",
        "\n",
        "Generate questions from your custom documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightningrod import QuestionPipeline\n",
        "\n",
        "pipeline_config = QuestionPipeline(\n",
        "    seed_generator=file_set_seed_generator,\n",
        "    question_generator=question_generator,\n",
        "    labeler=labeler,\n",
        "    renderer=renderer,\n",
        ")\n",
        "\n",
        "dataset = client.transforms.run(pipeline_config, max_questions=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install pandas\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Download samples to memory\n",
        "samples = dataset.download()\n",
        "print(f\"Generated {dataset.num_rows} samples\\n\")\n",
        "\n",
        "# Convert cached samples to a list of dictionaries\n",
        "rows = dataset.flattened()\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "print(df.head())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
